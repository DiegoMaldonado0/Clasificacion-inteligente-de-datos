{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tutorial sobre el perceptrón**"
      ],
      "metadata": {
        "id": "X2k4i-QiGrXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fundamentos de la técnica**\n",
        "\n",
        "El perceptrón es el modelo más simple de una red neuronal artificial. Fue propuesto por Frank Rosenblatt en 1958 y se utiliza principalmente para la clasificación binaria lineal, es decir, para separar los datos en dos clases dentro de un espacio R en n dimensiones (línea, plano o hiperplano)\n",
        "\n",
        "Su funcionamiento se basa en:\n",
        "\n",
        "\n",
        "*   Recibir entradas númericas ($x_1, x_2, ..., x_n$).\n",
        "*   Multiplicar dichas entradas por pesos ($w_1, w_2, ..., w_n$).\n",
        "*   Sumar un bias ($b$).\n",
        "*   Pasar el resultado a través de una función de activación ($f$, que suele ser una función escalón o función sigmoide).\n",
        "*   Producir una salida binaria (0 o 1).\n",
        "\n",
        "El perceptrón aprende ajustando los pesos durante las épocas ejecutadas en la fase de entrenamiento, minimizando los errores en la clasificación de los datos.\n",
        "Dichos ajustes se realizan con el valor learning rate ($\\eta$).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N1McOls4DsJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo matemático del perceptrón**\n",
        "\n",
        "El modelo del perceptrón es expresado de la siguiente forma:\n",
        "\n",
        "$$\n",
        "y = f\\left(\\sum_{i=1}^{n} w_i x_i + b\\right)\n",
        "$$\n",
        "\n",
        "donde:\n",
        "*   $x_i$: variables de entrada.\n",
        "*   $w_i$: pesos asociados a cada entrada.\n",
        "*   $b$: bias.\n",
        "*   $f$: función de activación (por ejemplo, una función escalón).\n",
        "*   $y$: salida del modelo (0 o 1).\n",
        "\n",
        "**Función de activación escalón:**\n",
        "\n",
        "La función de activación escalón se encarga de tomar el valor producido por la expresión matemática, y transformarlo a 0 o 1 según la regla estipulada, por ejemplo:\n",
        "\n",
        "$$\n",
        "f(z) =\n",
        "\\begin{cases}\n",
        "1 & \\text{si } z \\ge 0 \\\\\n",
        "0 & \\text{si } z < 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "**Regla de actualización de pesos y bias:**\n",
        "\n",
        "Hay que recordar que durante el entrenamiento, los pesos se actualizan según la siguiente regla:\n",
        "\n",
        "$$\n",
        "w_i = w_i + \\eta (y_{real} - y_{predicho})x_i\n",
        "$$\n",
        "\n",
        "donde $\\eta$ es la tasa de aprendizaje, mientras que la operacion $(y_{real} - y_{predicho})$ representa el error.\n",
        "\n",
        "El bias se actualiza según la siguiente regla:\n",
        "\n",
        "$$\n",
        "b = b + b(y_{real} - y_{predicho})\n",
        "$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FuPW_X40Fqs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Librerías y funciones a emplear en Python**\n",
        "\n",
        "Para programar un perceptrón simple se puede hacer uso de la biblioteca **Scikit-learn**, una librería de machine learning común en Python, sin embargo, desarrollaremos un perceptrón desde cero para comprender cada uno de los puntos antes descritos."
      ],
      "metadata": {
        "id": "C1BwkQ4AMzDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Librería NumPy**\n",
        "\n",
        "Es una librería de código abierto especializada en el cálculo numérico y análisis de datos, en este caso solo usaremos algunas de sus funciones.\n",
        "\n",
        "\n",
        "\n",
        "*   **.array**: Crea un array a partir de una lista de valores.\n",
        "*   **.random.rand**: Se utiliza para generar números aleatorios distribuidos de forma uniforme en el intervalo [0, 1).\n",
        "*   **.dot**: Usado para calcular el producto punto (o producto escalar) entre dos arrays, su sintaxis es numpy.dot(a,b), dónde a y b son los arrays de entrada.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YBNCtjd6NeiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "mRMh1G7fQjG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función de activación**\n",
        "\n",
        "En esta ocasión se utilizará una función escalón, que asignara el valor 1 a cualquier resultado **mayor o igual** a 0, y asignara el valor 0 a cualquier resultado diferente."
      ],
      "metadata": {
        "id": "ucP6wileU4hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_function(z):\n",
        "  if z >= 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "P2wKnWbFVVjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline**"
      ],
      "metadata": {
        "id": "oJ60vhYHRa6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**\n",
        "\n",
        "Definiremos las variables de entrada y de salida en el problema a resolver. En este caso seran los datos de la compuerta lógica OR."
      ],
      "metadata": {
        "id": "ZR7KRZSORlRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) # Datos de entrada\n",
        "y = np.array([0, 1, 1, 1]) # Salidas esperadas"
      ],
      "metadata": {
        "id": "OJVob3dTSINP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection**\n",
        "\n",
        "Las razones por las que elegimos un perceptrón son:\n",
        "*   Es un clasificador lineal.\n",
        "*   Tiene una interpretación matemática sencilla.\n",
        "*   Resuelve problemas linealmente separables (como el presentado).\n",
        "*   Su algoritmo permite ajustar los pesos de sus entradas de forma automática, esto lo vuelve útil en problemas de aprendizaje supervisado.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fiV6dpzuSo4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**\n",
        "\n",
        "En esta sección escribiremos el código necesario para el entrenamiento del perceptrón, recordemos que ya contamos con las variables de entrada y los resultados esperados."
      ],
      "metadata": {
        "id": "sjnGeGY1TbPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero es necesario inicializar de forma aleatoria los pesos y el bias, además de crear un learning rate para el ajuste de los pesos tras cada época que contenga errores en las predicciones."
      ],
      "metadata": {
        "id": "hjuTlAZ2YXxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.random.rand(2) # Pesos\n",
        "b = np.random.rand() # Bias\n",
        "n = 0.1 # Learning rate mencionado anteriormente para el ajuste de pesos"
      ],
      "metadata": {
        "id": "SNHwEAgWYrpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora definiremos el código de entrenamiento del perceptrón."
      ],
      "metadata": {
        "id": "qsqlRtWlYvWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0\n",
        "while True:\n",
        "  epoch += 1\n",
        "  total_error = 0\n",
        "  print(\"-\"*20 + f\" Epoch: {epoch} \" + \"-\"*20)\n",
        "\n",
        "  for i in range(len(X)):\n",
        "    # Cálculo del resultado del perceptrón\n",
        "    z = np.dot(X[i], w) + b # Representación del modelo matemático explicado!\n",
        "    y_pred = activation_function(z)\n",
        "\n",
        "    #Cálculo del error\n",
        "    error = y[i] - y_pred # Serán operaciones como 0-0, 1-0, etc.\n",
        "    total_error += error ** 2\n",
        "\n",
        "    # Mostrar operaciones aritméticas\n",
        "    print(f\"\\nPatrón {i + 1}: Entrada = {X[i]}, Salida Esperada = {y[i]}, Salida Predicha = {y_pred}\")\n",
        "    print(f\"Error = {error}\")\n",
        "    print(f\"Pesos actuales: w = {w}, bias = {b}\")\n",
        "\n",
        "    # AJUSTE DE PESOS Y BIAS EN CASO DE ERRORES EXISTENTES!\n",
        "    if error != 0:\n",
        "      w += n * error * X[i] # Regla de actualización de pesos expuesta anteriormente\n",
        "      b += n * error # Regla de actualización del bias expuesta anteriormente\n",
        "      print(f\"Pesos actualizados: w = {w}, bias = {b}\")\n",
        "\n",
        "  if total_error == 0:\n",
        "    print(\"El entrenamiento ha finalizado, no hay error en ninguno de los patrones analizados\")\n",
        "    print(\"Épocas ejecutadas:\" + str(epoch))\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "cmmcdlm4W5YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**\n",
        "\n",
        "Prueba del perceptrón entrenado para verificar que el entrenamiento fue adecuado."
      ],
      "metadata": {
        "id": "UtqIZlBYbyg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X)):\n",
        "  z = np.dot(X[i], w) + b\n",
        "  y_pred = activation_function(z)\n",
        "  print(f\"Entrada: {X[i]}, Salida Esperada: {y[i]}, Salida Predicha: {y_pred}\")"
      ],
      "metadata": {
        "id": "gVtiQ3Ibb880"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**\n",
        "\n",
        "Ahora calcularemos la precisión del perceptrón (Accuracy). Este valor mide qué proporción de las predicciones fueron correctas.\n",
        "\n",
        "Su fórmula es:\n",
        "\n",
        "$$ Accuracy = NúmeroDeAciertos \\div TotalDeMuestras $$\n",
        "\n",
        "Esta es una implementación en Python:"
      ],
      "metadata": {
        "id": "dkCeYngld7M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "for i in range(len(X)):\n",
        "  z = np.dot(X[i], w) + b\n",
        "  y_pred = activation_function(z)\n",
        "\n",
        "  if y_pred == y[i]:\n",
        "    correct += 1\n",
        "\n",
        "  accuracy = correct / len(X)\n",
        "\n",
        "  print(f\"Entrada: {X[i]}, Salida Esperada: {y[i]}, Salida Predicha: {y_pred}\")\n",
        "\n",
        "print(f\"Número de aciertos: {correct}\")\n",
        "print(f\"Número de muestras: {len(X)}\")\n",
        "print(f\"Precisión: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KkXrnFDsfjsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referencias Bibliográficas**\n",
        "\n",
        "First artificial neural network. (2023, October 26). Guinness World Records. https://www.guinnessworldrecords.com/world-records/760225-first-artificial-neural-network\n",
        "\n",
        "Ahmad, M. S. (n.d.). Neural network: perceptron. https://www.101ai.net/nnet/perceptron\n",
        "\n",
        "Serengil, S. (2021, May 26). A step by step perceptron example - Sefik Ilkin Serengil. Sefik Ilkin Serengil. https://sefiks.com/2020/01/04/a-step-by-step-perceptron-example/?authuser=0\n",
        "\n",
        "Alberca, A. S. (2022, May 12). La librería Numpy | Aprende con Alf. Aprende Con Alf. https://aprendeconalf.es/docencia/python/manual/numpy/\n",
        "\n",
        "Joshi, S. (2023, January 30). NumPY Numpy.Random.rand() función. Delft Stack. https://www.delftstack.com/es/api/numpy/python-numpy-random.rand-function/\n",
        "\n",
        "Joseavinatecmm. (n.d.). IDC/line-based/perceptron-frscratch.ipynb at main · joseavinatecmm/IDC. GitHub. https://github.com/joseavinatecmm/IDC/blob/main/line-based/perceptron-frscratch.ipynb"
      ],
      "metadata": {
        "id": "fzE4g42YiAuy"
      }
    }
  ]
}